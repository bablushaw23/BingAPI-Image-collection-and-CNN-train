{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gatherImagesFromBingAPIThenTrainUsingCNNWith93%Acc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bablushaw23/BingAPI-Image-collection-and-CNN-train/blob/master/gatherImagesFromBingAPIThenTrainUsingCNNWith93_Acc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gD7XeZekUU6",
        "colab_type": "text"
      },
      "source": [
        "#Aqquiring dataset\n",
        "Here i am using Bing's API to gather images. To get it:\n",
        "\n",
        "*   Access Azure cognitive services through [link](https://azure.microsoft.com/en-us/try/cognitive-services/?apiSlug=search-api-v7&country=India&allowContact=true&unauthorized=1#_=_)\n",
        "*   Find Search API tab\n",
        "\n",
        "*   There you'll find bing Search API v7\n",
        "*   It includes image search\n",
        "* Go and aquire your API key\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJiWox6eadwK",
        "colab_type": "text"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHZdJX1haFJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import statements\n",
        "import requests\n",
        "from matplotlib import pyplot\n",
        "from requests import exceptions\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qk7K10OaWE7",
        "colab_type": "text"
      },
      "source": [
        "**My private keys and settings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE-zloHkaVSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "API_KEY = \"ee402fbf91ba438a961ee37f6f99ebeb\"       # my API key, (might be expire now)\n",
        "MAX_RESULTS = 30\n",
        "GROUP_SIZE = 10\n",
        "URL = \"https://api.cognitive.microsoft.com/bing/v7.0/images/search\"\n",
        "ACCEPTABLE_FILE_SIZE=1024   #bytes\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ-J4cHSal6L",
        "colab_type": "text"
      },
      "source": [
        "**Making parent directory of all downloaded images**\n",
        "\n",
        "*  This will make a directory under content folder within google colab home directory.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DYxqOJNalbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "directory='RawDatasets'\n",
        "if not os.path.exists(directory):\n",
        "  os.makedirs(directory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXCAEpzd--qS",
        "colab_type": "code",
        "outputId": "89d664cb-9dde-478f-94cb-c5da4af44734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ACTORS=['shahrukh khan', 'akshay kumar', 'aamir khan', 'salman khan', 'ayushmann khurrana', 'ranveer singh',\n",
        "       'Narendra modi','Donald trump', 'Mukesh ambani','A R rahman','Arijit singh', 'M S Dhoni','Virat kohli',\n",
        "       'Arun jetley','Sachin tendulkar']\n",
        "len(ACTORS)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTS7fB5bXSlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "EXCEPTIONS = set([IOError, FileNotFoundError,\n",
        "\texceptions.RequestException, exceptions.HTTPError,\n",
        "\texceptions.ConnectionError, exceptions.Timeout])\n",
        "\n",
        "\n",
        "\n",
        "ACTORS=['shahrukh khan', 'akshay kumar', 'aamir khan', 'salman khan', 'ayushmann khurrana', 'ranveer singh',\n",
        "       'Narendra modi','Donald trump', 'Mukesh ambani','A R rahman','Arijit singh', 'M S Dhoni','Virat kohli',\n",
        "       'Arun jetley','Sachin tendulkar']\n",
        "\n",
        "for actor in ACTORS:  \n",
        "  term = actor\n",
        "  if not os.path.exists(directory+'/'+term):\n",
        "    os.makedirs(directory+'/'+term)\n",
        "  \n",
        "  headers = {\"Ocp-Apim-Subscription-Key\" : API_KEY}\n",
        "  params = {\"q\": term, \"offset\": 0, \"count\": GROUP_SIZE}\n",
        "\n",
        "  # make the search\n",
        "  print(\"\\nSearching Bing API for '{}'\".format(term))\n",
        "  search = requests.get(URL, headers=headers, params=params)\n",
        "  search.raise_for_status()\n",
        "\n",
        "  # grab the results from the search, including the total number of\n",
        "  # estimated results returned by the Bing API\n",
        "  results = search.json()\n",
        "  estNumResults = min(results[\"totalEstimatedMatches\"], MAX_RESULTS)\n",
        "  print(\"Found {} results for '{}'.\".format(estNumResults,term))\n",
        "  total = 0\n",
        "  for offset in range(0, estNumResults, GROUP_SIZE):\n",
        "    print(\"Making request for group {}-{} of {}...\".format(offset, offset + GROUP_SIZE,\n",
        "                                                                  estNumResults))\n",
        "    params[\"offset\"] = offset\t  \n",
        "    search = requests.get(URL, headers=headers, params=params)\n",
        "    search.raise_for_status()\n",
        "    results = search.json()\n",
        "\t  \n",
        "\t  #print(\"Saving images for group {}-{} of {}...\".format(\n",
        "\t\t# offset, offset + GROUP_SIZE, estNumResults))\n",
        "    \n",
        "    for v in results[\"value\"]:\n",
        "      \n",
        "      try:\n",
        "        r = requests.get(v[\"contentUrl\"], timeout=30)\n",
        "        ext = v[\"contentUrl\"][v[\"contentUrl\"].rfind(\".\"):]\n",
        "\t\t\t   # build the path to the output image\n",
        "\t\t\t  \n",
        "        filename = os.path.sep.join([directory,term, \"{}{}\".format(str(total).zfill(8), ext)])\n",
        "\n",
        "\t\t\t   # write the image to disk\n",
        "        f = open(filename, \"wb\")\n",
        "        f.write(r.content)\n",
        "        f.close()\n",
        "\n",
        "\t\t  # catch any errors that would not unable us to download the image\n",
        "      except Exception as e:\n",
        "        if type(e) in EXCEPTIONS:\n",
        "          print(\"Skipping this for  error\")\n",
        "          continue\n",
        "      \n",
        "      if os.path.getsize(filename)<ACCEPTABLE_FILE_SIZE or :\n",
        "        os.remove(filename)\n",
        "        continue\n",
        "      \n",
        "      \n",
        "      total+=1 \n",
        "print(\"\\nAll processes fetching done...\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvveIA0zjud9",
        "colab_type": "text"
      },
      "source": [
        "# **Cropping only to face**\n",
        "For this i am using MTCNN packages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yMY4f4_msWz",
        "colab_type": "text"
      },
      "source": [
        "Downloading MTCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhUzAtdlmDVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install MTCNN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSRNv1iBvR1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r cropped_faces"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYu1tPX0nrSV",
        "colab_type": "text"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ0NE4Drm27p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mtcnn.mtcnn import MTCNN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVBg9x7Gn2GM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_faces(directory):    \n",
        "    dest='cropped_faces'\n",
        "    passed=[]\n",
        "    failed=[]\n",
        "    totalFiles=0\n",
        "    detector = MTCNN()\n",
        "    for Dir in os.listdir(directory):\n",
        "        aDir=os.path.join(directory, Dir)\n",
        "        print(\"In directory: \"+Dir)\n",
        "        for file in os.listdir(aDir):            \n",
        "            aFile=os.path.join(aDir, file)\n",
        "            if os.path.isfile(aFile):                \n",
        "                totalFiles+=1\n",
        "                # load image from file\n",
        "                \n",
        "                try:\n",
        "                    pixels = pyplot.imread(aFile)\n",
        "                    # detect faces in the image\n",
        "                    faces = detector.detect_faces(pixels)\n",
        "\n",
        "                    # display faces on the original image\n",
        "                    #print(aFile)\n",
        "                    \n",
        "                    for face in range(len(faces)):\n",
        "                        x1,y1,width,height=faces[face]['box']\n",
        "                        x2,y2=x1+width, y1+height\n",
        "                        x1=abs(x1)\n",
        "                        x2=abs(x2)\n",
        "                        y1=abs(y1)\n",
        "                        y2=abs(y2)\n",
        "                        dest_dir=os.path.join(dest, Dir)\n",
        "                        if not os.path.exists(dest_dir):\n",
        "                            os.makedirs(dest_dir)\n",
        "                        pyplot.imsave( dest_dir+'/'+str(face)+file, pixels[y1:y2, x1:x2])                    \n",
        "                    passed.append(aFile)\n",
        "                except:\n",
        "                    failed.append(aFile)\n",
        "    print(\"Printing failed list..............\")\n",
        "    print(failed)\n",
        "    print(\"Printed failed list..............\")\n",
        "    print(\"Total files: \",totalFiles)\n",
        "    print(\"Passed: \",len(passed))\n",
        "    print(\"Failed: \",len(failed))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUFR0kKQoGA0",
        "colab_type": "text"
      },
      "source": [
        "Calling save_faces()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYUcbFzLoJ01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "save_faces(directory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38gUqleewi9y",
        "colab_type": "text"
      },
      "source": [
        "**Size of Contents of cropped_faces folder is not so heavy**\n",
        "So i suggest you to transfer it to your googl drive,\n",
        "Because API key will not last for too long....\n",
        "\n",
        "*   If you want to do so,\n",
        "*   Run below 2 sections of codes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBiyB91uwXkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgR_anbEwhqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r cropped_faces 'drive/My Drive'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x4LCO1Xkg0X",
        "colab_type": "text"
      },
      "source": [
        "# Read images back from drive into cropped_faces\n",
        " Its my personal view not to make my drive dirty and do all work on temporary sample_data. If you want so then,\n",
        "1. Mount drive to colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SfWrxBQlEv-",
        "colab_type": "code",
        "outputId": "874c23d0-1918-4a66-bfb2-3213b1ef47a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrEfaTchcg3r",
        "colab_type": "text"
      },
      "source": [
        "2. Copy cropped_faces to local\n",
        "\n",
        "  While copying the images, i had to face some issues for which i had to close the browser's tab so to re-open and get chance to re-mount. If you' re facing any issue while running the below code then try on your own at first... re-starting should be the last option."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQvLYL-bcsoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r 'drive/My Drive/cropped_faces' 'sample_data'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxypY_rDqFYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('sample_data/cropped_faces/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV-IYIx8o0x7",
        "colab_type": "text"
      },
      "source": [
        "#All data are ready , now making ready to train..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKxxerCiqEK5",
        "colab_type": "text"
      },
      "source": [
        "**Making testing and valid datasets**\n",
        "\n",
        "This below code will create train and valid folders and \n",
        "\n",
        "> Then each category set will have entry as sub-folder in train and valid then\n",
        "\n",
        "> as per val_percentage's value each set will divide randomly into 2 parts and copied into train and valid\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkWNBmiqqCKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#needed to shuffle lists\n",
        "import random\n",
        "#to copy files\n",
        "from shutil import copyfile\n",
        "#some constants\n",
        "\n",
        "train_dir=\"train\"\n",
        "val_dir=\"valid\"\n",
        "val_percentage=15   # from 0 to 100\n",
        "\n",
        "dataSets=os.listdir()\n",
        "\n",
        "\"\"\"\n",
        "dataSets should include only category folders, not train and valid\n",
        "\"\"\"\n",
        "if train_dir not in dataSets:\n",
        "    os.mkdir(train_dir)\n",
        "else:\n",
        "    dataSets.pop(dataSets.index(train_dir))\n",
        "\n",
        "if val_dir not in dataSets:\n",
        "    os.mkdir(val_dir)\n",
        "else:\n",
        "    dataSets.pop(dataSets.index(val_dir))\n",
        "\n",
        "train_loc = os.path.realpath(train_dir)\n",
        "val_loc = os.path.realpath(val_dir)\n",
        "\n",
        "for each_set in dataSets:    \n",
        "    \n",
        "    population=len(os.listdir(each_set))     # total numbers of images in each_set\n",
        "    train_file_numbers=int(population*(100-val_percentage)/100)\n",
        "    random.shuffle(os.listdir(each_set))\n",
        "    shuffled_list=os.listdir(each_set)\n",
        "\n",
        "    fileLocn=os.path.join(train_loc,each_set)    \n",
        "    os.makedirs(fileLocn)        # creating sub-folders\n",
        "    \n",
        "    train_set= shuffled_list[:train_file_numbers]       # selecting first train_file_numbers\n",
        "    \n",
        "    for each_file in train_set:\n",
        "        src =os.path.join(os.getcwd(),each_set,each_file)        \n",
        "        copyfile(src, os.path.join(fileLocn, each_file))            #copying to train folders\n",
        "        \n",
        "    fileLocn=os.path.join(val_loc,each_set)\n",
        "    os.makedirs(fileLocn)\n",
        "    \n",
        "    valid_set = shuffled_list[train_file_numbers: ]         # selecting remaining images \n",
        "\n",
        "    for each_file in valid_set:\n",
        "        src =os.path.join(os.getcwd(),each_set,each_file)        \n",
        "        copyfile(src, os.path.join(fileLocn, each_file))           #copying to valid folders"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2Sv4EgN8rN_",
        "colab_type": "text"
      },
      "source": [
        "**Downloading required packages**\n",
        "\n",
        "Maybe skipped if already available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzQHTa8R81dw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP2-Bovm-C5S",
        "colab_type": "code",
        "outputId": "6494c771-5b61-4f50-d1e0-e5d4182a4fe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/sample_data/cropped_faces'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfYs0xN8pMYZ",
        "colab_type": "text"
      },
      "source": [
        "**Importing all required packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSPSS09eepFw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6517a285-9886-4820-84ef-cb51218aba0f"
      },
      "source": [
        "from keras.preprocessing.image import *\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "from keras import regularizers\n",
        "from keras.optimizers import *\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)    # for logging errors, helpful"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpVuC54LerEX",
        "colab_type": "text"
      },
      "source": [
        "**Model building now**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hugK5r4ulXil",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "72d3c242-b545-4a10-f226-511a3814e4a0"
      },
      "source": [
        "BATCH_SIZE=10\n",
        "IMG_SHAPE=150\n",
        "\n",
        "reg=10**(np.random.uniform(-4,0))\n",
        "lr=10**(np.random.uniform(-3,-4))\n",
        "\n",
        "train_image_generator      = ImageDataGenerator(rescale=1./255)  # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255)  # Generator for our validation data\n",
        "\n",
        "TRAIN_DIR=os.path.join(os.getcwd(),'train')\n",
        "VALID_DIR=os.path.join(os.getcwd(),'valid')\n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE, \n",
        "                                                           directory=TRAIN_DIR, \n",
        "                                                           shuffle=True, \n",
        "                                                           target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150) \n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=BATCH_SIZE, \n",
        "                                                              directory=VALID_DIR,\n",
        "                                                              shuffle=False,\n",
        "                                                              target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)\n",
        "                                                              class_mode='categorical')\n",
        "\n",
        "#MODEL 1\n",
        "\n",
        "#model = tf.keras.models.Sequential([\n",
        "#    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "#    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "#\n",
        "#    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "#    tf.keras.layers.MaxPooling2D(2,2),\n",
        "#    \n",
        "#    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "#    tf.keras.layers.MaxPooling2D(2,2),\n",
        "#    \n",
        "#    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "#    tf.keras.layers.MaxPooling2D(2,2),\n",
        "#    \n",
        "#    tf.keras.layers.Flatten(),\n",
        "#    tf.keras.layers.Dense(512, activation='relu'),\n",
        "#    tf.keras.layers.Dense(6, activation='softmax')\n",
        "#])\n",
        "#    \n",
        "\n",
        "# COMPILE MODEL\n",
        "    \n",
        "#model.compile(optimizer='adam', \n",
        "#              loss='sparse_categorical_crossentropy',\n",
        "#              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "#MODEL 2\n",
        "\n",
        "#model=Sequential()\n",
        "\n",
        "#model.add( InputLayer( input_shape=[150,150,3] )  )\n",
        "\n",
        "#model.add( Conv2D( filters=14, kernel_size=5, strides=1, padding='same', activation='relu' ))\n",
        "#model.add(MaxPool2D(pool_size=5, padding='same'))\n",
        " \n",
        "#model.add( Conv2D( filters=40, kernel_size=5, strides=1, padding='same', activation='relu' ))\n",
        "#model.add(MaxPool2D(pool_size=5, padding='same'))\n",
        "\n",
        "#model.add( Conv2D( filters=100, kernel_size=5, strides=1, padding='same', activation='relu' ))\n",
        "#model.add(MaxPool2D(pool_size=5, padding='same'))\n",
        "\n",
        "#model.add(Dropout(0.25))\n",
        "#model.add(Flatten())\n",
        "#model.add(Dense(6, activation='relu'))\n",
        "#model.add(Dropout(rate=0.5))\n",
        "#optimizer=Adam(lr=1e-3)\n",
        "\n",
        "#model.compile(optimizer=optimizer, \n",
        "#              loss='categorical_crossentropy',\n",
        "#              metrics=['accuracy'])    \n",
        "\n",
        "\n",
        "#MODEL 3\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(IMG_SHAPE,IMG_SHAPE,3)))\n",
        "\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512,activation='relu',kernel_regularizer=regularizers.l2(reg)))\n",
        "\n",
        "model.add(Dense(len(ACTORS) ,activation='sigmoid',kernel_regularizer=regularizers.l2(reg)))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=lr),\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 383 images belonging to 15 classes.\n",
            "Found 74 images belonging to 15 classes.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 15)                7695      \n",
            "=================================================================\n",
            "Total params: 3,460,303\n",
            "Trainable params: 3,460,303\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeUmjnTyf2-p",
        "colab_type": "text"
      },
      "source": [
        "**The time is now, Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QggNt-iCf-B1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "05a11ef4-c8ff-4c60-ae91-39465a2206ba"
      },
      "source": [
        "def totalFiles(directory):\n",
        "    total = 0\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        total += len(files)\n",
        "    return total\n",
        "\n",
        "EPOCHS = 100\n",
        "total_train=totalFiles(TRAIN_DIR)\n",
        "total_val=totalFiles(VALID_DIR)\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=int(np.ceil(total_val / float(BATCH_SIZE)))\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "39/39 [==============================] - 2s 58ms/step - loss: 0.2563 - acc: 0.9333 - val_loss: 0.2563 - val_acc: 0.9333\n",
            "Epoch 2/100\n",
            "39/39 [==============================] - 2s 54ms/step - loss: 0.2560 - acc: 0.9333 - val_loss: 0.2549 - val_acc: 0.9333\n",
            "Epoch 3/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2563 - acc: 0.9333 - val_loss: 0.2578 - val_acc: 0.9333\n",
            "Epoch 4/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2568 - acc: 0.9333 - val_loss: 0.2548 - val_acc: 0.9333\n",
            "Epoch 5/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2560 - acc: 0.9333 - val_loss: 0.2552 - val_acc: 0.9333\n",
            "Epoch 6/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2564 - acc: 0.9333 - val_loss: 0.2553 - val_acc: 0.9333\n",
            "Epoch 7/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2564 - acc: 0.9333 - val_loss: 0.2547 - val_acc: 0.9333\n",
            "Epoch 8/100\n",
            "39/39 [==============================] - 2s 54ms/step - loss: 0.2562 - acc: 0.9333 - val_loss: 0.2553 - val_acc: 0.9333\n",
            "Epoch 9/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2562 - acc: 0.9333 - val_loss: 0.2557 - val_acc: 0.9333\n",
            "Epoch 10/100\n",
            "39/39 [==============================] - 2s 51ms/step - loss: 0.2561 - acc: 0.9333 - val_loss: 0.2543 - val_acc: 0.9333\n",
            "Epoch 11/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2565 - acc: 0.9333 - val_loss: 0.2544 - val_acc: 0.9333\n",
            "Epoch 12/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2560 - acc: 0.9333 - val_loss: 0.2545 - val_acc: 0.9333\n",
            "Epoch 13/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2558 - acc: 0.9333 - val_loss: 0.2551 - val_acc: 0.9333\n",
            "Epoch 14/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2568 - acc: 0.9333 - val_loss: 0.2545 - val_acc: 0.9333\n",
            "Epoch 15/100\n",
            "39/39 [==============================] - 2s 54ms/step - loss: 0.2556 - acc: 0.9333 - val_loss: 0.2582 - val_acc: 0.9333\n",
            "Epoch 16/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2566 - acc: 0.9333 - val_loss: 0.2551 - val_acc: 0.9333\n",
            "Epoch 17/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2562 - acc: 0.9333 - val_loss: 0.2545 - val_acc: 0.9333\n",
            "Epoch 18/100\n",
            "39/39 [==============================] - 2s 51ms/step - loss: 0.2564 - acc: 0.9333 - val_loss: 0.2554 - val_acc: 0.9333\n",
            "Epoch 19/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2563 - acc: 0.9333 - val_loss: 0.2561 - val_acc: 0.9333\n",
            "Epoch 20/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2562 - acc: 0.9333 - val_loss: 0.2547 - val_acc: 0.9333\n",
            "Epoch 21/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2562 - acc: 0.9333 - val_loss: 0.2553 - val_acc: 0.9333\n",
            "Epoch 22/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2560 - acc: 0.9333 - val_loss: 0.2552 - val_acc: 0.9333\n",
            "Epoch 23/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2561 - acc: 0.9333 - val_loss: 0.2557 - val_acc: 0.9333\n",
            "Epoch 24/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2561 - acc: 0.9333 - val_loss: 0.2546 - val_acc: 0.9333\n",
            "Epoch 25/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2560 - acc: 0.9333 - val_loss: 0.2549 - val_acc: 0.9333\n",
            "Epoch 26/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2560 - acc: 0.9333 - val_loss: 0.2549 - val_acc: 0.9333\n",
            "Epoch 27/100\n",
            "39/39 [==============================] - 2s 51ms/step - loss: 0.2562 - acc: 0.9333 - val_loss: 0.2544 - val_acc: 0.9333\n",
            "Epoch 28/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2562 - acc: 0.9333 - val_loss: 0.2543 - val_acc: 0.9333\n",
            "Epoch 29/100\n",
            "39/39 [==============================] - 2s 55ms/step - loss: 0.2560 - acc: 0.9333 - val_loss: 0.2557 - val_acc: 0.9333\n",
            "Epoch 30/100\n",
            "39/39 [==============================] - 2s 54ms/step - loss: 0.2564 - acc: 0.9333 - val_loss: 0.2545 - val_acc: 0.9333\n",
            "Epoch 31/100\n",
            "39/39 [==============================] - 2s 54ms/step - loss: 0.2557 - acc: 0.9333 - val_loss: 0.2549 - val_acc: 0.9333\n",
            "Epoch 32/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2560 - acc: 0.9333 - val_loss: 0.2545 - val_acc: 0.9333\n",
            "Epoch 33/100\n",
            "39/39 [==============================] - 2s 54ms/step - loss: 0.2564 - acc: 0.9333 - val_loss: 0.2549 - val_acc: 0.9333\n",
            "Epoch 34/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2561 - acc: 0.9333 - val_loss: 0.2555 - val_acc: 0.9333\n",
            "Epoch 35/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2557 - acc: 0.9333 - val_loss: 0.2548 - val_acc: 0.9333\n",
            "Epoch 36/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2560 - acc: 0.9333 - val_loss: 0.2554 - val_acc: 0.9333\n",
            "Epoch 37/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2562 - acc: 0.9333 - val_loss: 0.2548 - val_acc: 0.9333\n",
            "Epoch 38/100\n",
            "39/39 [==============================] - 2s 51ms/step - loss: 0.2557 - acc: 0.9333 - val_loss: 0.2547 - val_acc: 0.9333\n",
            "Epoch 39/100\n",
            "39/39 [==============================] - 2s 50ms/step - loss: 0.2558 - acc: 0.9333 - val_loss: 0.2544 - val_acc: 0.9333\n",
            "Epoch 40/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2556 - acc: 0.9333 - val_loss: 0.2548 - val_acc: 0.9333\n",
            "Epoch 41/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2557 - acc: 0.9333 - val_loss: 0.2556 - val_acc: 0.9333\n",
            "Epoch 42/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2560 - acc: 0.9333 - val_loss: 0.2544 - val_acc: 0.9333\n",
            "Epoch 43/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2553 - acc: 0.9333 - val_loss: 0.2543 - val_acc: 0.9333\n",
            "Epoch 44/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2556 - acc: 0.9333 - val_loss: 0.2550 - val_acc: 0.9333\n",
            "Epoch 45/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2556 - acc: 0.9333 - val_loss: 0.2541 - val_acc: 0.9333\n",
            "Epoch 46/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2553 - acc: 0.9333 - val_loss: 0.2549 - val_acc: 0.9333\n",
            "Epoch 47/100\n",
            "39/39 [==============================] - 2s 54ms/step - loss: 0.2552 - acc: 0.9333 - val_loss: 0.2548 - val_acc: 0.9333\n",
            "Epoch 48/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2554 - acc: 0.9333 - val_loss: 0.2541 - val_acc: 0.9333\n",
            "Epoch 49/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2551 - acc: 0.9333 - val_loss: 0.2541 - val_acc: 0.9333\n",
            "Epoch 50/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2548 - acc: 0.9333 - val_loss: 0.2555 - val_acc: 0.9333\n",
            "Epoch 51/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2552 - acc: 0.9333 - val_loss: 0.2543 - val_acc: 0.9333\n",
            "Epoch 52/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2550 - acc: 0.9333 - val_loss: 0.2541 - val_acc: 0.9333\n",
            "Epoch 53/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2552 - acc: 0.9333 - val_loss: 0.2537 - val_acc: 0.9333\n",
            "Epoch 54/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2551 - acc: 0.9333 - val_loss: 0.2539 - val_acc: 0.9333\n",
            "Epoch 55/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2553 - acc: 0.9333 - val_loss: 0.2538 - val_acc: 0.9333\n",
            "Epoch 56/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2550 - acc: 0.9333 - val_loss: 0.2548 - val_acc: 0.9333\n",
            "Epoch 57/100\n",
            "39/39 [==============================] - 2s 51ms/step - loss: 0.2551 - acc: 0.9333 - val_loss: 0.2544 - val_acc: 0.9333\n",
            "Epoch 58/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2552 - acc: 0.9333 - val_loss: 0.2543 - val_acc: 0.9333\n",
            "Epoch 59/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2551 - acc: 0.9333 - val_loss: 0.2539 - val_acc: 0.9333\n",
            "Epoch 60/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2549 - acc: 0.9333 - val_loss: 0.2540 - val_acc: 0.9333\n",
            "Epoch 61/100\n",
            "39/39 [==============================] - 2s 51ms/step - loss: 0.2554 - acc: 0.9333 - val_loss: 0.2555 - val_acc: 0.9333\n",
            "Epoch 62/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2554 - acc: 0.9333 - val_loss: 0.2541 - val_acc: 0.9333\n",
            "Epoch 63/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2554 - acc: 0.9333 - val_loss: 0.2545 - val_acc: 0.9333\n",
            "Epoch 64/100\n",
            "39/39 [==============================] - 2s 50ms/step - loss: 0.2551 - acc: 0.9333 - val_loss: 0.2541 - val_acc: 0.9333\n",
            "Epoch 65/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2555 - acc: 0.9333 - val_loss: 0.2545 - val_acc: 0.9333\n",
            "Epoch 66/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2552 - acc: 0.9333 - val_loss: 0.2542 - val_acc: 0.9333\n",
            "Epoch 67/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2553 - acc: 0.9333 - val_loss: 0.2544 - val_acc: 0.9333\n",
            "Epoch 68/100\n",
            "39/39 [==============================] - 2s 51ms/step - loss: 0.2551 - acc: 0.9333 - val_loss: 0.2541 - val_acc: 0.9333\n",
            "Epoch 69/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2549 - acc: 0.9333 - val_loss: 0.2544 - val_acc: 0.9333\n",
            "Epoch 70/100\n",
            "39/39 [==============================] - 2s 51ms/step - loss: 0.2553 - acc: 0.9333 - val_loss: 0.2539 - val_acc: 0.9333\n",
            "Epoch 71/100\n",
            "39/39 [==============================] - 2s 54ms/step - loss: 0.2553 - acc: 0.9333 - val_loss: 0.2545 - val_acc: 0.9333\n",
            "Epoch 72/100\n",
            "39/39 [==============================] - 2s 51ms/step - loss: 0.2553 - acc: 0.9333 - val_loss: 0.2547 - val_acc: 0.9333\n",
            "Epoch 73/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2551 - acc: 0.9333 - val_loss: 0.2542 - val_acc: 0.9333\n",
            "Epoch 74/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2551 - acc: 0.9333 - val_loss: 0.2538 - val_acc: 0.9333\n",
            "Epoch 75/100\n",
            "39/39 [==============================] - 2s 51ms/step - loss: 0.2552 - acc: 0.9333 - val_loss: 0.2539 - val_acc: 0.9333\n",
            "Epoch 76/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2552 - acc: 0.9333 - val_loss: 0.2551 - val_acc: 0.9333\n",
            "Epoch 77/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2555 - acc: 0.9333 - val_loss: 0.2546 - val_acc: 0.9333\n",
            "Epoch 78/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2552 - acc: 0.9333 - val_loss: 0.2551 - val_acc: 0.9333\n",
            "Epoch 79/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2551 - acc: 0.9333 - val_loss: 0.2542 - val_acc: 0.9333\n",
            "Epoch 80/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2555 - acc: 0.9333 - val_loss: 0.2542 - val_acc: 0.9333\n",
            "Epoch 81/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2550 - acc: 0.9333 - val_loss: 0.2539 - val_acc: 0.9333\n",
            "Epoch 82/100\n",
            "39/39 [==============================] - 2s 51ms/step - loss: 0.2549 - acc: 0.9333 - val_loss: 0.2550 - val_acc: 0.9333\n",
            "Epoch 83/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2555 - acc: 0.9333 - val_loss: 0.2544 - val_acc: 0.9333\n",
            "Epoch 84/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2553 - acc: 0.9333 - val_loss: 0.2545 - val_acc: 0.9333\n",
            "Epoch 85/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2552 - acc: 0.9333 - val_loss: 0.2538 - val_acc: 0.9333\n",
            "Epoch 86/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2550 - acc: 0.9333 - val_loss: 0.2542 - val_acc: 0.9333\n",
            "Epoch 87/100\n",
            "39/39 [==============================] - 2s 51ms/step - loss: 0.2550 - acc: 0.9333 - val_loss: 0.2542 - val_acc: 0.9333\n",
            "Epoch 88/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2553 - acc: 0.9333 - val_loss: 0.2541 - val_acc: 0.9333\n",
            "Epoch 89/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2553 - acc: 0.9333 - val_loss: 0.2542 - val_acc: 0.9333\n",
            "Epoch 90/100\n",
            "39/39 [==============================] - 2s 51ms/step - loss: 0.2549 - acc: 0.9333 - val_loss: 0.2538 - val_acc: 0.9333\n",
            "Epoch 91/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2551 - acc: 0.9333 - val_loss: 0.2538 - val_acc: 0.9333\n",
            "Epoch 92/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2553 - acc: 0.9333 - val_loss: 0.2540 - val_acc: 0.9333\n",
            "Epoch 93/100\n",
            "39/39 [==============================] - 2s 54ms/step - loss: 0.2552 - acc: 0.9333 - val_loss: 0.2538 - val_acc: 0.9333\n",
            "Epoch 94/100\n",
            "39/39 [==============================] - 2s 51ms/step - loss: 0.2550 - acc: 0.9333 - val_loss: 0.2548 - val_acc: 0.9333\n",
            "Epoch 95/100\n",
            "39/39 [==============================] - 2s 51ms/step - loss: 0.2553 - acc: 0.9333 - val_loss: 0.2547 - val_acc: 0.9333\n",
            "Epoch 96/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2549 - acc: 0.9333 - val_loss: 0.2545 - val_acc: 0.9333\n",
            "Epoch 97/100\n",
            "39/39 [==============================] - 2s 53ms/step - loss: 0.2550 - acc: 0.9333 - val_loss: 0.2538 - val_acc: 0.9333\n",
            "Epoch 98/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2546 - acc: 0.9333 - val_loss: 0.2561 - val_acc: 0.9333\n",
            "Epoch 99/100\n",
            "39/39 [==============================] - 2s 52ms/step - loss: 0.2553 - acc: 0.9333 - val_loss: 0.2536 - val_acc: 0.9333\n",
            "Epoch 100/100\n",
            "39/39 [==============================] - 2s 54ms/step - loss: 0.2550 - acc: 0.9333 - val_loss: 0.2537 - val_acc: 0.9333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBnBTyvWiVWE",
        "colab_type": "text"
      },
      "source": [
        "# Lets, have a look on training graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAAzYrAAibVQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "37954a9f-b06f-4b60-dc49-b3bb57bbc506"
      },
      "source": [
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}